{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xml.dom.minidom\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, Birch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "questionaire_single = [\n",
    "    \"I feel sad.\",\n",
    "    \"I am discouraged about my future.\",\n",
    "    \"I always fail.\",\n",
    "    \"I don't get pleasure from things.\",\n",
    "    \"I feel quite guilty.\",\n",
    "    \"I expected to be punished.\",\n",
    "    \"I am disappointed in myself.\",\n",
    "    \"I always criticize myself for my faults.\",\n",
    "    \"I have thoughts of killing myself.\",\n",
    "    \"I always cry.\",\n",
    "    \"I am hard to stay still.\",\n",
    "    \"It's hard to get interested in things.\",\n",
    "    \"I have trouble making decisions.\",\n",
    "    \"I feel worthless.\",\n",
    "    \"I don't have energy to do things.\",\n",
    "    \"I have changes in my sleeping pattern.\",\n",
    "    \"I am always irritable.\",\n",
    "    \"I have changes in my appetite.\",\n",
    "    \"I feel hard to concentrate on things.\",\n",
    "    \"I am too tired to do things.\",\n",
    "    \"I have lost my interest in sex.\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "depression_texts = [\n",
    "    \"I feel depressed.\",\n",
    "    \"I am diagnosed with depression.\",\n",
    "    \"I am treating my depression.\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"processed/miniLM_L6_embs.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_posts = data[\"train_posts\"]\n",
    "train_mappings = data[\"train_mappings\"]\n",
    "train_tags = data[\"train_labels\"]\n",
    "train_embs = data[\"train_embs\"]\n",
    "test_posts = data[\"test_posts\"]\n",
    "test_mappings = data[\"test_mappings\"]\n",
    "test_tags = data[\"test_labels\"]\n",
    "test_embs = data[\"test_embs\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sbert = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "questionaire_single_embs = sbert.encode(questionaire_single)\n",
    "depression_embs = sbert.encode(depression_texts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# take care, require ~100G RAM\n",
    "train_posts = np.array(train_posts)\n",
    "test_posts = np.array(test_posts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "depression_pair_sim = cosine_similarity(train_embs, depression_embs)\n",
    "depression_pair_sim.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "depression_pair_sim_test = cosine_similarity(test_embs, depression_embs)\n",
    "depression_pair_sim_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "topK = 16\n",
    "os.makedirs(f\"processed/depress_sim{topK}\", exist_ok=True)\n",
    "os.makedirs(f\"processed/depress_sim{topK}/train\", exist_ok=True)\n",
    "os.makedirs(f\"processed/depress_sim{topK}/test\", exist_ok=True)\n",
    "for i, (mapping, label) in enumerate(zip(train_mappings, train_tags)):\n",
    "    posts = train_posts[mapping]\n",
    "    sim_scores = depression_pair_sim[mapping, 0]\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/depress_sim{topK}/train/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))\n",
    "\n",
    "for i, (mapping, label) in enumerate(zip(test_mappings, test_tags)):\n",
    "    posts = test_posts[mapping]\n",
    "    sim_scores = depression_pair_sim_test[mapping, 0]\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/depress_sim{topK}/test/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dimension_sim_single = cosine_similarity(train_embs, questionaire_single_embs)\n",
    "dimension_sim_single.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dimension_sim_single_test = cosine_similarity(test_embs, questionaire_single_embs)\n",
    "dimension_sim_single_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "combined_sim = np.concatenate([depression_pair_sim, dimension_sim_single], axis=1)\n",
    "combined_sim_test = np.concatenate([depression_pair_sim_test, dimension_sim_single_test], axis=1)\n",
    "combined_sim.shape, combined_sim_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "topK = 16\n",
    "os.makedirs(f\"processed/combined_maxsim{topK}\", exist_ok=True)\n",
    "os.makedirs(f\"processed/combined_maxsim{topK}/train\", exist_ok=True)\n",
    "os.makedirs(f\"processed/combined_maxsim{topK}/test\", exist_ok=True)\n",
    "for i, (mapping, label) in enumerate(zip(train_mappings, train_tags)):\n",
    "    posts = train_posts[mapping]\n",
    "    sim_scores = combined_sim[mapping].max(1)\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/combined_maxsim{topK}/train/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))\n",
    "\n",
    "for i, (mapping, label) in enumerate(zip(test_mappings, test_tags)):\n",
    "    posts = test_posts[mapping]\n",
    "    sim_scores = combined_sim_test[mapping].max(1)\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/combined_maxsim{topK}/test/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "topK = 16\n",
    "os.makedirs(f\"processed/questionaire_maxsim{topK}\", exist_ok=True)\n",
    "os.makedirs(f\"processed/questionaire_maxsim{topK}/train\", exist_ok=True)\n",
    "os.makedirs(f\"processed/questionaire_maxsim{topK}/test\", exist_ok=True)\n",
    "for i, (mapping, label) in enumerate(zip(train_mappings, train_tags)):\n",
    "    posts = train_posts[mapping]\n",
    "    sim_scores = dimension_sim_single[mapping].max(1)\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/questionaire_maxsim{topK}/train/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))\n",
    "\n",
    "for i, (mapping, label) in enumerate(zip(test_mappings, test_tags)):\n",
    "    posts = test_posts[mapping]\n",
    "    sim_scores = dimension_sim_single_test[mapping].max(1)\n",
    "    top_ids = sim_scores.argsort()[-topK:]\n",
    "    top_ids = np.sort(top_ids)  # sort in time order\n",
    "    sel_posts = posts[top_ids]\n",
    "    with open(f\"processed/questionaire_maxsim{topK}/test/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "topK = 16\n",
    "os.makedirs(f\"processed/last{topK}\", exist_ok=True)\n",
    "os.makedirs(f\"processed/last{topK}/train\", exist_ok=True)\n",
    "os.makedirs(f\"processed/last{topK}/test\", exist_ok=True)\n",
    "for i, (mapping, label) in enumerate(zip(train_mappings, train_tags)):\n",
    "    posts = train_posts[mapping]\n",
    "    sel_posts = posts[-topK:]\n",
    "    with open(f\"processed/last{topK}/train/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))\n",
    "\n",
    "for i, (mapping, label) in enumerate(zip(test_mappings, test_tags)):\n",
    "    posts = test_posts[mapping]\n",
    "    sel_posts = posts[-topK:]\n",
    "    with open(f\"processed/last{topK}/test/{i:06}_{label}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(x.replace(\"\\n\", \" \") for x in sel_posts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}