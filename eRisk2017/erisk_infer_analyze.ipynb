{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from data import HierDataModule\n",
    "from data import infer_preprocess\n",
    "from ERDE import ERDE_sample\n",
    "from model import HierClassifier\n",
    "from transformers import AutoTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from collections import defaultdict, Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from model import HierClassifier\n",
    "from ERDE import ERDE_chunk\n",
    "import xml.dom.minidom\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HierClassifier.load_from_checkpoint(\n",
    "    \"[pretrained ckpt]\"\n",
    ")\n",
    "clf.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(clf.model_type)\n",
    "max_len = clf.hparams.max_len\n",
    "max_posts = 16\n",
    "clf.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed/miniLM_L6_embs.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_posts = data[\"train_posts\"]\n",
    "train_mappings = data[\"train_mappings\"]\n",
    "train_tags = data[\"train_labels\"]\n",
    "train_embs = data[\"train_embs\"]\n",
    "test_posts = data[\"test_posts\"]\n",
    "test_mappings = data[\"test_mappings\"]\n",
    "test_tags = data[\"test_labels\"]\n",
    "test_embs = data[\"test_embs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer('paraphrase-MiniLM-L6-v2').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_texts = [\n",
    "    \"I feel depressed.\",\n",
    "    \"I am diagnosed with depression.\",\n",
    "    \"I am treating my depression.\"\n",
    "]\n",
    "questionaire_single = [\n",
    "    \"I feel sad.\",\n",
    "    \"I am discouraged about my future.\",\n",
    "    \"I always fail.\",\n",
    "    \"I don't get pleasure from things.\",\n",
    "    \"I feel quite guilty.\",\n",
    "    \"I expected to be punished.\",\n",
    "    \"I am disappointed in myself.\",\n",
    "    \"I always criticize myself for my faults.\",\n",
    "    \"I have thoughts of killing myself.\",\n",
    "    \"I always cry.\",\n",
    "    \"I am hard to stay still.\",\n",
    "    \"It's hard to get interested in things.\",\n",
    "    \"I have trouble making decisions.\",\n",
    "    \"I feel worthless.\",\n",
    "    \"I don't have energy to do things.\",\n",
    "    \"I have changes in my sleeping pattern.\",\n",
    "    \"I am always irritable.\",\n",
    "    \"I have changes in my appetite.\",\n",
    "    \"I feel hard to concentrate on things.\",\n",
    "    \"I am too tired to do things.\",\n",
    "    \"I have lost my interest in sex.\"\n",
    "]\n",
    "\n",
    "template_embeddings = sbert.encode(depression_texts+questionaire_single)\n",
    "template_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred_probas = []\n",
    "user_basis = []\n",
    "num_updates_users = []\n",
    "num_posts_users = []\n",
    "for mappings in tqdm(test_mappings, total=len(test_mappings)):\n",
    "    user_posts = [test_posts[i] for i in mappings[::-1]]\n",
    "    pred_probas = []\n",
    "    posts_bank = []\n",
    "    embedding_bank = None\n",
    "    scores_bank = []\n",
    "    basis_bank = []\n",
    "    num_updates = 0\n",
    "    for pid, new_post in enumerate(user_posts):\n",
    "        # new_post = \"\"\n",
    "        # new_emb = sbert.encode(new_post).reshape(1, -1)\n",
    "        new_emb = test_embs[mappings[pid]].reshape(1, -1)\n",
    "        new_scores = cosine_similarity(new_emb, template_embeddings)[0]\n",
    "        best_template_id = new_scores.argmax()\n",
    "        new_score = new_scores[best_template_id]\n",
    "        # take all new posts before capacity is all used\n",
    "        if len(posts_bank) < max_posts:\n",
    "            posts_bank.insert(0, new_post)\n",
    "            scores_bank.insert(0, new_score)\n",
    "            basis_bank.insert(0, best_template_id)\n",
    "            batch = infer_preprocess(tokenizer, posts_bank, max_len)\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits, attn_score = clf([batch])\n",
    "            num_updates += 1\n",
    "            proba = torch.sigmoid(logits).detach().cpu().item()\n",
    "            pred_probas.append(proba)\n",
    "            continue\n",
    "        min_id = np.argmin(scores_bank)\n",
    "        if new_score >= scores_bank[min_id]:\n",
    "            del posts_bank[min_id]\n",
    "            del scores_bank[min_id]\n",
    "            del basis_bank[mid_id]\n",
    "            posts_bank.insert(0, new_post)\n",
    "            scores_bank.insert(0, new_score)\n",
    "            basis_bank.insert(0, best_template_id)\n",
    "            # make prediction\n",
    "            batch = infer_preprocess(tokenizer, posts_bank, max_len)\n",
    "            for k, v in batch.items():\n",
    "                batch[k] = v.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits, attn_score = clf([batch])\n",
    "            num_updates += 1\n",
    "            proba = torch.sigmoid(logits).detach().cpu().item()\n",
    "            pred_probas.append(proba)\n",
    "            # TODO stop if meet condition\n",
    "        else:\n",
    "            pred_probas.append(pred_probas[-1])\n",
    "            # do nothing, save time\n",
    "            pass\n",
    "    sample_pred_probas.append(pred_probas)\n",
    "    num_updates_users.append(num_updates)\n",
    "    num_posts_users.append(len(user_posts))\n",
    "    user_basis.append(basis_bank)\n",
    "len(sample_pred_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_updates_users = pd.Series(num_updates_users)\n",
    "num_posts_users = pd.Series(num_posts_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"num_user_posts\": num_posts_users.describe(),\n",
    "    \"num_infers\": num_updates_users.describe(),\n",
    "    \"infer_portion\": (num_updates_users / num_posts_users).describe()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portion of actual model inferences\n",
    "(num_updates_users.sum() / num_posts_users.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERDE5 = ERDE_sample(sample_pred_probas, test_tags, threshold=0.5, o=5)\n",
    "ERDE50 = ERDE_sample(sample_pred_probas, test_tags, threshold=0.5, o=50)\n",
    "print(ERDE5, ERDE50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_texts(texts):\n",
    "    batch = infer_preprocess(tokenizer, texts, max_len)\n",
    "    for k, v in batch.items():\n",
    "        batch[k] = v.cuda()\n",
    "    with torch.no_grad():\n",
    "        logits, attn_score = clf([batch])\n",
    "    return torch.sigmoid(logits).detach().cpu().item(), attn_score[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000385_1.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000360_1.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000365_1.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000370_1.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000000_0.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./processed/combined_maxsim16/test/000001_0.txt\"\n",
    "texts = open(fname).readlines()\n",
    "prob, attn_score = infer_texts(texts)\n",
    "print(\"Depression prob\", prob)\n",
    "for text, attn in zip(texts, attn_score):\n",
    "    print(attn, text.strip()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deb5c85a0d181f020663b0781bb785da64b0ac73c1b94407b759932d81dbf297"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('py36': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
