{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import gzip\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from filter_subreddits import filter_subs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# analyze subreddits\n",
    "subreddit_cnts = defaultdict(int)\n",
    "all_users = set()\n",
    "for fname in tqdm(glob(\"../emnlp-2020-mental-health-generalization/data/processed/reddit/wolohan/*.submissions.tar.gz\")):\n",
    "    with gzip.open(fname, \"r\") as f:\n",
    "        data0 = json.load(f)\n",
    "    user = data0[0][\"user_id_str\"]\n",
    "    all_users.add(user)\n",
    "    for record in data0:\n",
    "        subreddit_cnts[record['subreddit']] += 1\n",
    "\n",
    "for fname in tqdm(glob(\"../emnlp-2020-mental-health-generalization/data/processed/reddit/wolohan/*.comments.tar.gz\")):\n",
    "    with gzip.open(fname, \"r\") as f:\n",
    "        data0 = json.load(f)\n",
    "    user = data0[0][\"user_id_str\"]\n",
    "    all_users.add(user)\n",
    "    for record in data0:\n",
    "        subreddit_cnts[record['subreddit']] += 1\n",
    "subreddit_cnts = pd.Series(subreddit_cnts).sort_values(ascending=False)\n",
    "print(subreddit_cnts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "subreddit_cnts[\"depression\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for dataset, subs in filter_subs.items():\n",
    "    intersection = set(subreddit_cnts.index.tolist()) & subs\n",
    "    print(dataset, len(subs), len(intersection))\n",
    "    print(subreddit_cnts[list(intersection)].sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "random.seed(2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# the same set of users across filtering strategy\n",
    "MIN_POSTS = 32\n",
    "users_split = {\"train\": [], \"val\": [], \"test\": []}\n",
    "for user in all_users:\n",
    "    tmp = random.random()\n",
    "    if tmp < 0.1:\n",
    "        users_split[\"test\"].append(user)\n",
    "    elif 0.1 <= tmp < 0.2:\n",
    "        users_split[\"val\"].append(user)\n",
    "    else:\n",
    "        users_split[\"train\"].append(user)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for filter_type in ['Depression', 'RSDD', 'All Mental Health']:\n",
    "for filter_type in ['All Mental Health']:\n",
    "    print(filter_type)\n",
    "    out_dir = f\"split_filter_{filter_type.replace(' ', '-')}\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    all_user_submissions = defaultdict(list)\n",
    "    all_user_submissions_utc = defaultdict(list)\n",
    "    all_user_comments = defaultdict(list)\n",
    "    all_user_comments_utc = defaultdict(list)\n",
    "    all_labels = {}\n",
    "    for fname in tqdm(glob(\"../emnlp-2020-mental-health-generalization/data/processed/reddit/wolohan/*.submissions.tar.gz\")):\n",
    "        with gzip.open(fname, \"r\") as f:\n",
    "            data0 = json.load(f)\n",
    "        user = data0[0][\"user_id_str\"]\n",
    "        label0 = int(data0[0][\"depression\"] == \"depression\")\n",
    "        for record in data0:\n",
    "            if record['subreddit'] in filter_subs[filter_type]:\n",
    "                continue\n",
    "            title = \" \".join(record[\"title_tokenized\"])\n",
    "            text = ' '.join(record[\"text_tokenized\"])\n",
    "            utc = int(record[\"created_utc\"])\n",
    "            all_labels[user] = label0\n",
    "            all_user_submissions[user].append(title+\"\\n\"+text)\n",
    "            all_user_submissions_utc[user].append(utc)\n",
    "\n",
    "    for fname in tqdm(glob(\"../emnlp-2020-mental-health-generalization/data/processed/reddit/wolohan/*.comments.tar.gz\")):\n",
    "        with gzip.open(fname, \"r\") as f:\n",
    "            data0 = json.load(f)\n",
    "        user = data0[0][\"user_id_str\"]\n",
    "        for record in data0:\n",
    "            if record['subreddit'] in filter_subs[filter_type]:\n",
    "                continue\n",
    "            text = ' '.join(record[\"text_tokenized\"])\n",
    "            utc = int(record[\"created_utc\"])\n",
    "            all_user_comments[user].append(text)\n",
    "            all_user_comments_utc[user].append(utc)\n",
    "    \n",
    "    print({k: len(v) for k, v in users_split.items()})\n",
    "    for split, users in users_split.items():\n",
    "        with open(f\"{out_dir}/{split}.pkl\", \"wb\") as f:\n",
    "            user_posts = []\n",
    "            labels = []\n",
    "            for user in tqdm(users):\n",
    "                if user not in all_labels:\n",
    "                    continue\n",
    "                label0 = all_labels[user]\n",
    "                posts0 = all_user_submissions[user] + all_user_comments[user]\n",
    "                times0 = all_user_submissions_utc[user] + all_user_comments_utc[user]\n",
    "                if len(posts0) < MIN_POSTS:\n",
    "                    continue\n",
    "                # sort by ascending time\n",
    "                sorted_posts = [pair[0] for pair in sorted(zip(posts0, times0), key=lambda x: x[1])]\n",
    "                user_posts.append(posts0)\n",
    "                labels.append(label0)\n",
    "            print(split, len(labels))\n",
    "            pickle.dump([user_posts, labels], f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)"
  },
  "interpreter": {
   "hash": "deb5c85a0d181f020663b0781bb785da64b0ac73c1b94407b759932d81dbf297"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}